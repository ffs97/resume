\documentclass[11pt, letter]{resume}
\geometry{left=0.8in, top=0.7in, right=0.8in, bottom=0.7in, footskip=0.3in}

\name{Gurpreet}{Singh}
\position{B. Tech{\enskip\cdotp\enskip}Department of Computer Science and Engineering}

\mobile{(+91) 9005528086}
\email{guggu@iitk.ac.in}
\homepage{fat-fighter.github.io}
\github{fat-fighter}
\linkedin{fat-fighter}

\def\company{Company Name }
\def\profile{Job Title }

\lettertitle{Job Application for \profile}
\letteropening{Dear Sir / Ma'am,}
\letterclosing{Sincerely,}
%\letterenclosure[Attached]{Curriculum Vitae}

\begin{document}

\makecvheader[C]
\makecvfooter
  {\today}
  {Gurpreet Singh \ \cdotp \ Cover Letter}
  {}

\makelettertitle
\begin{cvletter}

	I have been researching openings at \company with great interest and came
	across the advertisement for \profile on your website careers page. I
	believe my skills and experience could be a great match with your
	organization’s initiatives and culture and, therefore, have decided to
	apply for the said position.

	I have always been fascinated by the intricate machine, that is the
	personal computer. I started programming when I was 14 years old, and have
	been hooked since. During my high school, I learned to code in the Visual
	Basic environment and dabbled in web development. I had decided at that
	time to get a degree in computer science and started preparing for the
	Joint Entrance Examination (JEE), an admit to the top technological
	institutes in India, the IITs. After two years of arduous preparation and
	competing with more than a million aspirants, I qualified in the top 0.12\%
	of those who took the JEE Advanced test. Presently, I am a senior in the
	Department of Computer Science and Engineering at Indian Institute of
	Technology Kanpur.

	It wasn’t until the sophomore year that I discovered Machine Learning,
	through Prof. Andrew Ng’s Course on Coursera. Fascinated by the concepts
	discussed in the course and in order to probe deeper into machine learning,
	I decided to go for an internship in a leading unicorn startup in the field
	of mobile advertising, Inmobi. During this internship, I looked at ways of
	feature extraction for ad creative images and built interpretable
	regression models to predict the click rate of an ad based on actionable
	features. The internship allowed me to look into some theoretical aspects
	of machine learning, particularly regression, and gain practical knowledge
	on building simple interpretable models.

	Summer of 2018 saw me working at Goldman Sachs (GS) where I worked in the
	Corporate Treasury Strats team on augmenting features to existing models
	for Asset Liability Gap management. In another project at GS, I developed a
	greedy strategy for customer margin allocation to maximize internalization
	in the firm, taking various parameters into consideration. Through these
	internships, I was exposed to the working of the industrial world, and they
	helped me connect with many people. These experiences helped me build my
	development skills and afforded me chances to solve real-world problems in
	different sectors. Attributed to these internships, I have substantial
	experience in the industry.

	During my junior and senior years, I have undertaken multiple courses in
	machine learning, including “Introduction to Machine Learning”, “Natural
	Language Processing” and “Data Mining”. I have also completed a course on
	“Probabilistic Modelling and Inference” under Prof. Piyush Rai, which
	particularly piqued my interest.  It was this course that introduced me to
	formal methods in probabilistic machine learning and laid the foundations
	of my interest in Approximate Inference and Bayesian Optimization. Another
	riveting course I have done at IITK is “Statistical and Algorithmic
	Learning Theory” under Prof. Purushottam Kar, which introduced me to
	concepts in learning theory, particularly statistical convergence analysis
	of algorithms.

	Apart from the coursework, I have done a number of projects during my
	undergraduate study up till now. I worked on a reading comprehension task
	on the SQuAD dataset under the supervision of Prof. Harish Karnick, in the
	“Natural Language Processing” course. In another course project under Prof.
	Purushottam Kar, I worked on an incremental method to train two-layer
	neural networks (single hidden layer) by presenting a (two-layer) network
	as an ensemble and incrementally training each node in the hidden layer
	using boosting, particularly Gradient Boosting. Using this incremental
	training as a pre-training step prior to applying backpropagation afforded
	interesting results on some simple datasets. In the same course, I did a
	survey on the convergence of different techniques for convex optimization
	such as Vanilla Gradient Descent (Vanilla GD), Stochastic GD, NAG, etc.,
	and also studied the non-convergence of Adam.

	During my junior year, I did a project as part of the course “Probabilistic
	Modelling and Inference” under Prof. Piyush Rai on clustering in arbitrary
	shapes. We surveyed several models based on clustering in the latent space.
	Moreover, we proposed a novel Mixture of Experts model using the clustering
	embeddings discovered in Variational Deep Embeddings (VaDE) model as a
	gating function. I extended this work in another course project during my
	senior year, under the supervision of Prof. Arnab Bhattacharya. In order to
	overcome the slowed inference in VaDE, we proposed another model based on
	approximating the posterior of the cluster assignments using a deep neural
	network. The model built was shown to work better than VaDE at clustering
	tasks, with much faster inference. We further extended the model to be used
	as a gating function for ME models, and it was shown to be superior to some
	baseline gating functions.

	Presently, I am working with Prof. Piyush Rai on models for link prediction
	in graphs. So far in the project, I have extended an unpublished work to
	build a model combining the predictive properties of Graph Variational
	Autoencoders with the interpretability of variants of Stochastic Block
	Models (SBMs), more particularly Mixed Membership SBMs. In addition, I
	surveyed some of the state of the art smoothing and reparametrization
	tricks in Black Box Variational Inference for Discrete Latent Variable
	Models, particularly VAE styled models with RBM priors. Using the GumBolt
	trick, I was able to build a model which afforded superior results to most
	existing baselines on some graph datasets.

	The various projects I have pursued in my undergraduate study are evidence
	of my interest in research. Through each and every course and project, I
	have learned ways of understanding and implementing different machine
	learning algorithms and inference strategies. Through my internships and
	other projects, I have substantial development experience as well. Details
	of all my projects are given on my {\color{red}
	\href{https://fat-fighter.github.io}{webpage}}. Other than my cognition in
	Machine Learning, my technical expertise includes cross-platform
	proficiency (Windows, Linux and MacOS); fluency in scripting/programming
	languages such as C/C++, Python, JS and SQL. I am comfortable with
	Tensorflow and other tools for Machine Learning such as Scikit-Learn,
	Pandas, Weka, etc.

	With my technical skills, determination and interest in your firm, I
	believe I can make a valuable contribution to furthering your company’s
	success and goals. The resume attached with this application provides more
	information about my background. I thank you for your time and
	consideration. Looking forward to a positive reply.

\end{cvletter}
\makeletterclosing

\end{document}
